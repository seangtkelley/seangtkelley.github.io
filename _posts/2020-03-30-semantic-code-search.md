---
layout: post
title: "Semantic Code Search"
desc: "Last semester, I took the couse CS 585: Introduction to Natural Language Processing taught by Mohit Iyyer. As it is graduate level, a significant portion of the curriculum is centered around a team project. In this post, I would like to share our team's final report."
tag: "Machine Learning"
author: "Sean Kelley"
thumb: "https://techcrunch.com/wp-content/uploads/2015/04/codecode.jpg"
date: 2020-03-30
---

Last semester, I took the couse CS 585: Introduction to Natural Language Processing taught by Mohit Iyyer. As it is graduate level, a significant portion of the curriculum is centered around a team project. In this post, I would like to share our team's final report. 

After hearing about the launch of Github's [CodeSearchNet Challenge](https://github.blog/2019-09-26-introducing-the-codesearchnet-challenge/), we choose to conduct a small survey of different word embedding technique when integrated into the provided semantic search pipeline assembled by the Github team. For the tl;dr, we obtained quite interesting results with the Continuous Bag of Words embedding. The results of that model can be found on [Weights & Biases](http://app.wandb.ai/github/codesearchnet/runs/w4jtu67q/overview).

<embed src="/files/blog/2020-03-30-semantic-code-search/CS_585_Final_Report.pdf" width="100%" height="1000px" />